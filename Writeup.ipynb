{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Classifier\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "- Load the data set (see below for links to the project data set)\n",
    "- Explore, summarize and visualize the data set\n",
    "- Design, train and test a model architecture\n",
    "- Use the model to make predictions on new images\n",
    "- Analyze the softmax probabilities of the new images\n",
    "- Summarize the results with a written report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Basic overview:\n",
    "- Number of training examples = 34799\n",
    "- Number of testing examples = 34799\n",
    "- Number of validation examples = 34799\n",
    "- Image data shape = (32, 32, 3)\n",
    "- Number of classes = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of elements per class:\n",
    "\n",
    "![title](./writeup/classes_distr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes example:\n",
    "\n",
    "![title](./writeup/data_examples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data augmentation\n",
    "\n",
    "The training set is not particulary well balanced in terms of classes, I decided to artificialy generate new data for classes were the inbalance is the most meaningful (the amount of examples is below the avarage, taken from the class distribution).\n",
    "\n",
    "Unfortunately, the images in the traffic sign dataset are in a low resulotion and quality, therefore I decided not to use any techniques related to blurring, or noise adding. Otherwise even small change, could override the actual image content. I focused only on rotations and cropping images, which shouldn't decrease image quality.\n",
    "\n",
    "Classes distribution after augmentation:\n",
    "![title](./writeup/classes_distr_aug.png)\n",
    "\n",
    "Example of augmentented data:\n",
    "\n",
    "![title](./writeup/augmented_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data preprocessing consists of:\n",
    "- histogram equalization (in order to improve image contrast)\n",
    "- gray conversion (brings better results, as it seems like the network recognizes)\n",
    "- min/max normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model architecture\n",
    "\n",
    "The architecture bases on the LeNet architecture, which was extended in order to meet the accuracy of 0.93. I've also applied techniques known from AlexNet, like 'Local Response Normalization' and dropout.\n",
    "\n",
    "There is a set of methods, I wrote in order to make the network assembling easier. \n",
    "- conv2d creates weights, biases, applies convolutions and returns the result after relu function\n",
    "- fc creates fully connected layer, with a given set of inputs and outputs. Also applies relu\n",
    "- lrn is a simple wrapper for tf.nn.local_response_normalization to make the code more clean\n",
    "\n",
    "The overall architecture might be described as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layer 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution, filter size=(7, 7), filters = 24, strides = (1, 1)\n",
    "conv1 = conv2d(x, 7, 24, 1, 'conv1')\n",
    "# Max pooling: kernel=(2, 2), strides=(2, 2)\n",
    "conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "# Local response normalization\n",
    "conv1 = lrn(conv1, 2, 2e-05, 0.75, name = 'norm1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layer 2:\n",
    "\n",
    "Similary to AlexNet, just convolve, don't pool, as I don't want to shrink the filters to quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolution: filter size=(3,3), filters = 32, strides = (1, 1)\n",
    "conv2 = conv2d(conv1, 3, 32, 1, 'conv2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layer 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolution: filter size=(3,3), filters = 32, strides = (1, 1)\n",
    "conv3 = conv2d(conv2, 3, 32, 1, 'conv3')\n",
    "# Max pooling: kernel=(2, 2), strides=(2, 2)\n",
    "conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "# Local response normalization\n",
    "conv3 = lrn(conv3, 2, 2e-05, 0.75, name = 'norm3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Flatten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten before passing to fully connected layers\n",
    "fc0 = flatten(conv3)\n",
    "fc0 = tf.nn.dropout(fc0, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layer 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fully connected layer with relu: inputs=512, outputs=512\n",
    "fc1 = fc(fc0, 512, 512, 'fc1')\n",
    "fc1 = tf.nn.dropout(fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layer 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fully connected layer with relu: inputs=512, outputs=512\n",
    "fc2 = fc(fc1, 512, 512, 'fc2')\n",
    "fc2 = tf.nn.dropout(fc2, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected layer: inputs=512, outputs=43\n",
    "fc(fc2, 512, 43, 'logits', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Approach\n",
    "\n",
    "The starting point of assembling the classifier, was the LeNet, that was iteratively improved till meeting given accuracy. Every modification was verified against the performance improvemenent it brings. Finally I end up with a network described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training:\n",
    "- optimizer: Adam\n",
    "- learning_rate: 0.001\n",
    "- epochs: 10\n",
    "- batch_size: 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regularization:\n",
    "- dropout (training probability: 0.5, validation probability: 1.0)\n",
    "- weight decay: L2 loss, ratio = 0.001\n",
    "\n",
    "It's still to be discussed if dropout works well with weight decay, however applying such combination for the problem, showed an improvement in the increase of the final accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Layers visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
