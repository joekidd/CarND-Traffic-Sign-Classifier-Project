{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Classifier\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "- Load the data set (see below for links to the project data set)\n",
    "- Explore, summarize and visualize the data set\n",
    "- Design, train and test a model architecture\n",
    "- Use the model to make predictions on new images\n",
    "- Analyze the softmax probabilities of the new images\n",
    "- Summarize the results with a written report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Basic overview:\n",
    "- Number of training examples = 34799\n",
    "- Number of testing examples = 12630\n",
    "- Number of validation examples = 4410\n",
    "- Image data shape = (32, 32, 3)\n",
    "- Number of classes = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of elements per class:\n",
    "\n",
    "![title](./writeup/classes_distr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of examples per class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- count      43.000000 (number of classes)\n",
    "- mean      809.279070 (average number of examples per class)\n",
    "- std       626.750855\n",
    "- min       180.000000 (min number of examples per class)\n",
    "- 25%       285.000000\n",
    "- 50%       540.000000 (median)\n",
    "- 75%      1275.000000\n",
    "- max      2010.000000 (max number of examples per class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes example:\n",
    "\n",
    "![title](./writeup/data_examples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data augmentation\n",
    "\n",
    "Considering both the number of classes and confusion table, I determined the some of the classes needs to be extended by fake examples.\n",
    "\n",
    "Unfortunately, the images in the traffic sign dataset are in a low resulotion and quality, therefore I decided not to use any techniques related to blurring, or noise adding. Otherwise even small change, could override the actual image content. I focused only on rotations and cropping images, which shouldn't decrease image quality and also increased the brightness of the images randomly.\n",
    "\n",
    "Examples from the previous paragraph after augmentention:\n",
    "\n",
    "![title](./writeup/augmented_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data preprocessing consists of:\n",
    "- histogram equalization (in order to improve image contrast)\n",
    "- min/max normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I considered also converting images to grey, however it leaded to lower accuracy and difficulties in distinguishing some signs of the same shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model architecture\n",
    "\n",
    "The architecture bases on the LeNet architecture, which was extended in order to meet the accuracy of 0.93. I've also applied techniques known from AlexNet, like 'Local Response Normalization' and dropout.\n",
    "\n",
    "There is a set of methods, I wrote in order to make the network assembling easier. \n",
    "- conv2d creates weights, biases, applies convolutions and returns the result after relu function\n",
    "- fc creates fully connected layer, with a given set of inputs and outputs. Also applies relu\n",
    "- lrn is a simple wrapper for tf.nn.local_response_normalization to make the code more clean\n",
    "\n",
    "The overall architecture might be described as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convolution</td>\n",
       "      <td>filters=16,filter_size=7,strides=(1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max pooling</td>\n",
       "      <td>kernel=(2,2),strides=(2,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>local response normalization</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>convolution</td>\n",
       "      <td>filters=32,filter_size=3,strides=(1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>convolution</td>\n",
       "      <td>filters=32,filter_size=3,strides=(1,1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max pooling</td>\n",
       "      <td>kernel=(2,2),strides=(2,2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>local response normalization</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>flatten</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dropout</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>inputs=256,outs=256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dropout</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fully connected</td>\n",
       "      <td>inputs=256,outs=256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dropout</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fully connected (logits)</td>\n",
       "      <td>inputs=256,outs=43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           layer                                    info\n",
       "0                    convolution  filters=16,filter_size=7,strides=(1,1)\n",
       "1                    max pooling              kernel=(2,2),strides=(2,2)\n",
       "2   local response normalization                                     NaN\n",
       "3                    convolution  filters=32,filter_size=3,strides=(1,1)\n",
       "4                    convolution  filters=32,filter_size=3,strides=(1,1)\n",
       "5                    max pooling              kernel=(2,2),strides=(2,2)\n",
       "6   local response normalization                                     NaN\n",
       "7                        flatten                                     NaN\n",
       "8                        dropout                                     NaN\n",
       "9                fully connected                     inputs=256,outs=256\n",
       "10                       dropout                                     NaN\n",
       "11               fully connected                     inputs=256,outs=256\n",
       "12                       dropout                                     NaN\n",
       "13      fully connected (logits)                      inputs=256,outs=43"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"writeup/arch.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Approach\n",
    "\n",
    "The starting point of assembling the classifier, was the LeNet, that was iteratively improved till meeting given accuracy. Every modification was verified against the performance improvemenent it brings. Finally I end up with a network described above.\n",
    "\n",
    "I prefered to avoid reusing existing architecture, that would bring me directly to the solution. Therefore it's a network, which architecture was made while experimenting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training:\n",
    "\n",
    "Early stopping was implemented - if no improvement on validation set was made within 5 epochs, then training process is terminated. The model managed to obtain max accuracy of 0.991836734693877 on the validation set. Training was terminated after 33 epochs. \n",
    "\n",
    "- optimizer: Adam\n",
    "- learning_rate: 0.001\n",
    "- epochs: early stopping after 33 epochs.\n",
    "- batch_size: 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regularization:\n",
    "- dropout (training probability: 0.5, validation probability: 1.0)\n",
    "- weight decay: L2 loss, ratio = 0.001\n",
    "\n",
    "It's still to be discussed if dropout works well with weight decay, however applying such combination for the problem, showed an improvement in the increase of the final accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Accuracy\n",
    "\n",
    "The network obtains the accuracy of 0.97553444173 on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the confusion matrix for the validation set:\n",
    "\n",
    "![title](./writeup/confusion.png)\n",
    "\n",
    "\n",
    "## 7. Images from Google Street View\n",
    "\n",
    "\n",
    "Below you may find the extra images that were downloaded from the net:\n",
    "\n",
    "![title](./writeup/extra_images.png)\n",
    "\n",
    "I have tried to compare 30-speed limit and 50-speed limit as those images are quite similar. The network fails to distinguish those two particular examples, but also gives lower probability on the chosen class. The correct answer is the second one. \n",
    "\n",
    "However, it works well with other images and network responses gives ~100% sureness. To sum up it gives accuracy of 80% in total.\n",
    "\n",
    "<table>\n",
    "        <tr>\n",
    "            <td><img src=\"writeup/certainty0.png\"/></td>\n",
    "            <td><img src=\"writeup/certainty1.png\"/></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><img src=\"writeup/certainty2.png\"/></td>\n",
    "            <td><img src=\"writeup/certainty3.png\"/></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><img src=\"writeup/certainty4.png\"/></td>\n",
    "\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    "The issue might be solved by collecting more examples of 50 and 30-speed limits. However I will leave, as it demonstrates interesting properties of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Layers visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![title](./writeup/feature_map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
